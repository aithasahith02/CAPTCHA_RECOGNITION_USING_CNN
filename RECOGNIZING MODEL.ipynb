{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# THE DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Flatten\n",
    "from datetime import datetime\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from claptcha import Claptcha\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,os.path\n",
    "import imutils\n",
    "import random\n",
    "import string\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING CAPTCHAS RANDOMLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomString():\n",
    "    rndLetters = (random.choice(string.ascii_uppercase+string.digits) for _ in range(4))\n",
    "    return \"\".join(rndLetters)\n",
    "def match(str1, str2): \n",
    "    c, j = 0, 0\n",
    "    for i in str1:    \n",
    "        if str2.find(i)>= 0 and j == str1.find(i): \n",
    "            c += 1\n",
    "        j += 1\n",
    "    if c == 3 :\n",
    "        return 0.75\n",
    "    elif c == 2 :\n",
    "        return 0.5\n",
    "    elif c == 4 :\n",
    "        return 1\n",
    "    else :\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_1424\\2882395662.py:6: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  resample=Image.BICUBIC, noise=0.2)\n"
     ]
    }
   ],
   "source": [
    "captcha_text = []\n",
    "n = 2000\n",
    "for i in range(1,n):\n",
    "    text = randomString()\n",
    "    c = Claptcha(text, \"FreeMono.ttf\", (150,90),\n",
    "             resample=Image.BICUBIC, noise=0.2)\n",
    "    c.margin = (25,25)\n",
    "    text, _ = c.write('Generated_captchas\\\\'+text+'.png')\n",
    "    captcha_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series(captcha_text)\n",
    "a.to_csv('Captcha_label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING THE GENERATED CAPTCHAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captchas_folder = \"Generated_captchas/\"\n",
    "preprocessed_captchas = \"Preprocessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveimage(letter_text,letter_image):\n",
    "    path = os.path.join(preprocessed_captchas, letter_text)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    p = os.path.join(path, str(random.randint(1,10000))+\".png\")\n",
    "    cv2.imwrite(p, letter_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha_images=  glob.glob(os.path.join(captchas_folder, \"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAMPLE IMAGE PREPROCESSING AND DRAWING COUNTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(captcha_images[3])\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Image.open(captcha_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.getpixel((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "Image.fromarray(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "Image.fromarray(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\n",
    "image_copy = gray.copy()\n",
    "\n",
    "cv2.drawContours(image=image_copy, contours=contours, contourIdx=-1, color=(0, 255, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "\n",
    "cv2.imshow('None approximation', image_copy)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite('contours_none_image1.jpg', image_copy)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.drawContours(image,contours,1,(255,0,0),3)\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.drawContours(image,contours,0,(255,255,0),3)\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.drawContours(image,contours,-1,(255,0,0),3)\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contour in contours:\n",
    "    (x,y,w,h) = cv2.boundingRect(contour)\n",
    "    print(x,y,w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(thresh[0:thresh.shape[0],10:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVING PREPROCESSED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in captcha_images:\n",
    "    mystr = file.split('/')\n",
    "    value = mystr[-1].split('\\\\')[1].split('.')[0]\n",
    "    image = cv2.imread(file)\n",
    "    gray_scale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    image = cv2.threshold(gray_scale,0,255,cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)[1]\n",
    "    slicedImage = image[0:image.shape[0],10:40]\n",
    "    letter = value[0]\n",
    "    saveimage(letter,slicedImage) \n",
    "    slicedImage = image[0:image.shape[0],40:70]\n",
    "    letter = value[1]\n",
    "    saveimage(letter,slicedImage)\n",
    "    slicedImage = image[0:image.shape[0],70:100]\n",
    "    letter = value[2]\n",
    "    saveimage(letter,slicedImage)\n",
    "    slicedImage = image[0:image.shape[0],100:130]\n",
    "    letter = value[3]\n",
    "    saveimage(letter,slicedImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GETTING STARTED WITH TRAINING PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow_from_directory('Preprocessed/',\n",
    "target_size = (32, 32),\n",
    "class_mode = 'categorical',color_mode='grayscale')\n",
    "\n",
    "testing_set = test_datagen.flow_from_directory('Test_data//',\n",
    "target_size = (32, 32),\n",
    "class_mode = 'categorical',color_mode='grayscale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE NEURAL NETWORK ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520',write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (5, 5), input_shape = (32, 32, 1), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2),strides=(2,2)))\n",
    "classifier.add(Conv2D(32, (5, 5), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2),strides=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units = 500, activation = 'relu'))\n",
    "classifier.add(Dense(units = 36, activation = 'softmax'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier.fit(training_set,steps_per_epoch=20,epochs=100, callbacks=[tboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = training_set.class_indices\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRESERVING THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('captchaclassifier.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING MODEL AND DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captcha_model = load_model('captchaclassifier.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "captcha_image_files =  glob.glob(os.path.join('Test_data\\\\Test', \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_class = {v:k for k,v in d.items()}\n",
    "print(captcha_image_files)\n",
    "print(\"\\n\")\n",
    "print(dict_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# MAPPING THE LABELS WITH VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value(pred):\n",
    "    count =0\n",
    "    for i in pred[0] :\n",
    "        count+=1\n",
    "        if i >= 0.5:\n",
    "            return dict_class[count-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prediction logic for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0.0\n",
    "for file in captcha_image_files:\n",
    "    combine = []\n",
    "    mystr = file.split('\\\\')\n",
    "    value1 = mystr[-1].split('.')[0]\n",
    "    image = cv2.imread(file)\n",
    "    gray_scale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.threshold(gray_scale,0,255,cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)[1]\n",
    "    slicedImage = image[0:90,10:40]\n",
    "    resized = cv2.resize(slicedImage,(32,32))\n",
    "    img= np.expand_dims(resized,axis=2)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    \n",
    "    pred = captcha_model.predict(img)\n",
    "    \n",
    "    print((pred[0]))\n",
    "    \n",
    "    \n",
    "    first = find_value(pred)\n",
    "    print(first)\n",
    "    combine.append(first)\n",
    "     \n",
    "    ##\n",
    "    slicedImage = image[0:90,40:70]\n",
    "    resized = cv2.resize(slicedImage,(32,32))\n",
    "    img= np.expand_dims(resized,axis=2)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    \n",
    "    \n",
    "    pred = captcha_model.predict(img)\n",
    "    \n",
    "    print((pred[0]))\n",
    "    \n",
    "    \n",
    "    second = find_value(pred)\n",
    "    print(second)\n",
    "    combine.append(second)\n",
    "\n",
    "    ##\n",
    "    slicedImage = image[0:90,70:100]\n",
    "    resized = cv2.resize(slicedImage,(32,32))\n",
    "    img= np.expand_dims(resized,axis=2)\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    \n",
    "    pred = captcha_model.predict(img)\n",
    "    \n",
    "    print((pred[0]))\n",
    "    \n",
    "    \n",
    "    third = find_value(pred)\n",
    "    print(third)\n",
    "    combine.append(third)\n",
    "    print(combine)\n",
    "    \n",
    "    ##\n",
    "    slicedImage = image[0:90,100:130]\n",
    "    resized = cv2.resize(slicedImage,(32,32))\n",
    "    img= np.expand_dims(resized,axis=2)\n",
    "    img= np.expand_dims(img,axis=0)\n",
    "    pred = captcha_model.predict(img)\n",
    "    \n",
    "    print((pred[0]))\n",
    "    \n",
    "    \n",
    "    fourth = find_value(pred)\n",
    "    print(fourth)\n",
    "    combine.append(fourth)\n",
    "    print(combine)\n",
    "    \n",
    "    predict = ''.join(combine)\n",
    "    print(predict)\n",
    "    print(value1)\n",
    "    print(\"------------\")\n",
    "    result = match(value1,predict)\n",
    "    if result == 0.75 :\n",
    "        print(\"String Matched by 75%\")\n",
    "    elif result == 0.5 :\n",
    "        print(\"String Matched by 50%\")\n",
    "    elif result == 1 :\n",
    "        print(\"String Matched by 100%\")\n",
    "    else :\n",
    "        print(\"String havent matched\")\n",
    "    count+=match(value1,predict)\n",
    "    print(match(value1,predict))\n",
    "    '''if value1 == predict:\n",
    "        count+=1'''"
   ]
  },
 {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
